{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\n\nimport os\nprint(os.listdir(\"../input\"))\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport lightgbm as lgb\nimport xgboost as xgb\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn')\nsns.set(font_scale=1)\n\ntry:\n    import cudf as gd\n    import nvstrings\n    from librmm_cffi import librmm\n    from nvstring_workaround import get_unique_tokens,on_gpu,get_token_counts,is_in\n    from cudf_workaround import unique,rename_col,to_pandas,merge\nexcept:\n    print('cudf not imported')",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['sample_submission.csv', 'test.csv', 'train.csv']\ncudf not imported\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "random_state = 42\nnp.random.seed(random_state)\ndf_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "11e4e9f6ee5aabcb0783768e03e786f141677538"
      },
      "cell_type": "code",
      "source": "def augment(x,y,t=1, include_raw=True):\n    xs,xn = [],[]\n    for i in range(t):\n        mask = y>0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xs.append(x1)\n\n#     for i in range(t//2):\n#         mask = y==0\n#         x1 = x[mask].copy()\n#         ids = np.arange(x1.shape[0])\n#         for c in range(x1.shape[1]):\n#             np.random.shuffle(ids)\n#             x1[:,c] = x1[ids][:,c]\n#         xn.append(x1)\n\n    xs = np.vstack(xs)\n    #xn = np.vstack(xn) # it seems removing 0 augmentation is better with mtr features\n    ys = np.ones(xs.shape[0])\n    #yn = np.zeros(xn.shape[0])\n    if include_raw:\n        return np.vstack([x,xs]), np.concatenate([y,ys])\n    else:\n        return xs,ys",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2bac2796bb647af39fb8bdfbe295817f7f4c8dce"
      },
      "cell_type": "code",
      "source": "features = [col for col in df_train.columns if col not in ['target', 'ID_code']]\n#features = ['var_12','var_81'] # check these 2 features first\n# in future we can check 1 feature at a time\nX_test = df_test[features].values",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "20a221b86ee4fe50c371767c63a72f225752213c"
      },
      "cell_type": "code",
      "source": "def mtr_encodes(x,y,xt,xte,names,window_sizes=[20,50]):\n    names = names.copy()\n    x0,xt0,xte0 = x.copy(),xt.copy(),xte.copy()\n    x,xt,xte = [x0],[xt0],[xte0]\n    for i in range(x0.shape[1]):\n        print('feature mtr encoding',names[i])\n        a,b,c = mtr_encode(x0[:,i],y,xt0[:,i],xte0[:,i],window_sizes)\n        x.append(a)\n        xt.append(b)\n        xte.append(c)\n        names.extend(['%s_mtr_%d'%(names[i],j) for j in window_sizes])\n    x = np.hstack(x)\n    xt = np.hstack(xt)\n    xte = np.hstack(xte)\n    return x,xt,xte,names\n\ndef mtr_encode(x,y,xt,xte,window_sizes):\n    ids = np.arange(x.shape[0])\n    x1,x2,y1,y2 = train_test_split(ids,y, test_size=0.5, random_state=42,stratify=y)\n\n    xnew = np.zeros([x.shape[0],len(window_sizes)]).astype(np.float32)\n    _,xnew[x2],_ = mtr_pd(x[x1],y1,x[x2],None,window_sizes)\n    _,xnew[x1],_ = mtr_pd(x[x2],y2,x[x1],None,window_sizes)\n    _,xt,xte = mtr_pd(x,y,xt,xte,window_sizes)\n    return xnew,xt,xte\n\ndef mtr_pd(x,y,xt,xte,window_sizes):\n    col = 'mean_y'\n    tr = pd.DataFrame()\n    tr['y'] = y.astype(np.float32)\n    tr['x'] = x\n    df = tr.groupby('x').agg({'y':'mean'})\n    df.columns = [col]\n    df = df.reset_index()\n    df = df.sort_values('x')\n    \n    cols = []\n \n    for i in [df.shape[0]//ws for ws in window_sizes]:\n        df['mtr_%d'%i] = df[col].rolling(i,min_periods=1).mean()\n        cols.append('mtr_%d'%i)\n    tr = tr.merge(df,on='x',how='left')\n    te = pd.DataFrame()\n    te['x'] = xt\n    te = te.merge(df,on='x',how='left')\n\n    if xte is not None:\n        tes = pd.DataFrame()\n        tes['x'] = xte\n        tes = tes.merge(df,on='x',how='left')\n        #print('test null ratio %.4f'%(tes[cols[0]].isnull().sum()*1.0/tes.shape[0]))\n        f = open('mtr_null.txt','a')\n        ratio = tes[cols[0]].isnull().sum()*1.0/tes.shape[0]\n        f.write('test null ratio %.4f\\n'%(ratio))\n        xte = tes[cols].values\n        del tes\n        #print('valid null ratio %.4f'%(te[cols[0]].isnull().sum()*1.0/te.shape[0]))\n        ratio = te[cols[0]].isnull().sum()*1.0/te.shape[0]\n        f.write('valid null ratio %.4f\\n\\n'%(ratio))\n        f.close()\n    x,xt = tr[cols].values,te[cols].values\n    return x,xt,xte\n\ndef mtr_gd(x,y,xt,xte,window_sizes=[500,1000]):\n    col = 'mean_y'\n    tr = gd.DataFrame()\n    tr['y'] = y.astype(np.float32)\n    tr['x'] = np.ascontiguousarray(x)#.astype(np.float32)\n    tr['x'] = tr['x'].fillna(0)\n    #print(tr['x'].to_pandas().isnull().sum())\n    df = tr.groupby('x').agg({'y':'mean'})\n    df = df.sort_values('x')\n    pdf = to_pandas(df)\n    \n    cols = []\n    for i in window_sizes:\n        pdf['mtr_%d'%i] = pdf[col].rolling(i,min_periods=1).mean()\n        cols.append('mtr_%d'%i)\n    del df\n    df = gd.from_pandas(pdf)\n    tr = merge(tr,df,on='x',how='left')\n    tr = to_pandas(tr)\n   \n    te = gd.DataFrame()\n    te['x'] = np.ascontiguousarray(xt)\n    te = merge(te,df,on='x',how='left')\n    te = to_pandas(te)\n    if xte is not None:\n        tes = gd.DataFrame()\n        tes['x'] = np.ascontiguousarray(xte)\n        tes = merge(tes,df,on='x',how='left')\n        tes = to_pandas(tes)\n        #print('test null ratio %.4f'%(tes[cols[0]].isnull().sum()*1.0/tes.shape[0]))\n        f = open('mtr_null.txt','a')\n        ratio = tes[cols[0]].isnull().sum()*1.0/tes.shape[0]\n        f.write('test null ratio %.4f\\n'%(ratio))\n        xte = tes[cols].values\n        del tes\n        #print('valid null ratio %.4f'%(te[cols[0]].isnull().sum()*1.0/te.shape[0]))\n        ratio = te[cols[0]].isnull().sum()*1.0/te.shape[0]\n        f.write('valid null ratio %.4f\\n\\n'%(ratio))\n        f.close()\n    x,xt = tr[cols].values,te[cols].values\n    return x,xt,xte",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dc08d970b8832b71ef64a181142cb48d98b6c18e"
      },
      "cell_type": "code",
      "source": "xgb_params =  {\n    'objective': 'binary:logistic',\n    #'objective':'reg:linear',\n    'tree_method': 'gpu_hist',\n    'eta':0.1,\n    'nthread': 16,\n    'num_class':1,\n    'max_depth': 1,\n    'silent':1,\n    'subsample':0.5,\n    'colsample_bytree': 0.5,\n    'min_child_weight':100,\n    'eval_metric':'auc',\n}",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "374d98175ed11c2050dedcda4c59e9efc2f05ae4"
      },
      "cell_type": "code",
      "source": "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\noof = df_train[['ID_code', 'target']]\noof['predict'] = 0\npredictions = df_test[['ID_code']]\nval_aucs = []\nfeature_importance_df = pd.DataFrame()\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(df_train, df_train['target'])):\n    X_train, y_train = df_train.iloc[trn_idx][features], df_train.iloc[trn_idx]['target']\n    X_valid, y_valid = df_train.iloc[val_idx][features], df_train.iloc[val_idx]['target']\n    \n    N = 1\n    p_valid,yp = 0,0\n    for i in range(N):\n        # mtr\n        X_train0, X_valid0, X_test0,names = mtr_encodes(X_train.values,y_train,X_valid.values,\n                                X_test,names=features,window_sizes=[20, 50])\n        print(\"Training on mtr data...\")\n        train_dataset = xgb.DMatrix(X_train0,y_train)\n        valid_dataset = xgb.DMatrix(X_valid0,y_valid)\n        watchlist = [(train_dataset, 'train'), (valid_dataset, 'valid')]\n        xgb_mtr_clf = xgb.train(xgb_params,\n                                          train_dataset,\n                                          evals=watchlist,\n                                          num_boost_round=12000,\n                                          early_stopping_rounds=1000,\n                                          verbose_eval=100\n                                          )\n        # augmentation\n        print(\"Augmenting....\")\n        augments = 10\n        X_t, y_t = augment(X_train0, y_train.values, t=augments, include_raw=False)\n        print(\"Augmented data shape:\", X_t.shape)\n        X_t_prob = xgb_mtr_clf.predict(xgb.DMatrix(X_t))\n        threshold = np.percentile(X_t_prob, int(100/augments))\n        \n        X_t = np.vstack((X_train0,\n                   X_t[X_t_prob>=threshold,:]))\n        y_t = np.hstack((y_train, y_t[X_t_prob>=threshold]))\n        print(\"Selected augmented data shape:\", X_t.shape)\n        \n        X_t = pd.DataFrame(X_t,columns=names).astype('float32')\n        X_valid0 = pd.DataFrame(X_valid0,columns=names).astype('float32')\n        X_test0 = pd.DataFrame(X_test0,columns=names).astype('float32')\n        print(X_t.shape,X_valid0.shape,X_test0.shape)\n        assert X_t.shape[1]==X_valid0.shape[1]\n        assert X_t.shape[1]==X_test0.shape[1]\n\n        train_dataset = xgb.DMatrix(X_t,y_t)\n        valid_dataset = xgb.DMatrix(X_valid0,y_valid)\n        watchlist = [(train_dataset, 'train'), (valid_dataset, 'valid')]\n        xgb_clf = xgb.train(xgb_params,\n                                          train_dataset,\n                                          evals=watchlist,\n                                          num_boost_round=12000,\n                                          early_stopping_rounds=1000,\n                                          verbose_eval=100\n                                          )\n        best_iteration = xgb_clf.best_iteration + 50\n        \n        p_valid += xgb_clf.predict(valid_dataset, ntree_limit=best_iteration)\n        yp += xgb_clf.predict(xgb.DMatrix(X_test0), ntree_limit=best_iteration)\n\n    oof['predict'][val_idx] = p_valid/N\n    val_score = roc_auc_score(y_valid, p_valid)\n    val_aucs.append(val_score)\n    \n    predictions['fold{}'.format(fold+1)] = yp/N",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1f698e19c1c399db90cb98e698a08cc663dd8319"
      },
      "cell_type": "code",
      "source": "# submission\npredictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\npredictions.to_csv('all_predictions.csv', index=None)\nsub_df = pd.DataFrame({\"ID_code\":df_test[\"ID_code\"].values})\nsub_df[\"target\"] = predictions['target']\nsub_df.to_csv(\"submission.csv\", index=False)\noof.to_csv('oof.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1b774f25807e92586c0726e71cdefb69a0ed5c24"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}